{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wiener SBND Closure Test for 1mu1p Measurement Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib as mpl\n",
    "from os import path\n",
    "import sys\n",
    "import uproot\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append('/exp/sbnd/app/users/munjung/xsec/wienersvd/cafpyana/analysis_village/unfolding')\n",
    "from wienersvd import *\n",
    "from unfolding_inputs import *\n",
    "\n",
    "# import dunestyle.matplotlib as dunestyle\n",
    "plt.style.use(\"presentation.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig = False\n",
    "save_fig_dir = \"/exp/sbnd/data/users/munjung/plots/wiener_svd/1mu1p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = mpl.cm.viridis\n",
    "norm = mpl.colors.Normalize(vmin=0.0, vmax=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_split(file):\n",
    "    this_split_df = pd.read_hdf(file, key=\"split\")\n",
    "    this_n_split = this_split_df.n_split.iloc[0]\n",
    "    return this_n_split\n",
    "\n",
    "def print_keys(file):\n",
    "    with pd.HDFStore(file, mode='r') as store:\n",
    "        keys = store.keys()       # list of all keys in the file\n",
    "        print(\"Keys:\", keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dfs(file, keys2load):\n",
    "    out_df_dict = {}\n",
    "    this_n_keys = get_n_split(file)\n",
    "    n_concat = min(n_max_concat, this_n_keys)\n",
    "    for key in keys2load:\n",
    "        dfs = []  # collect all splits for this key\n",
    "        for i in range(n_concat):\n",
    "            this_df = pd.read_hdf(file, key=f\"{key}_{i}\")\n",
    "            dfs.append(this_df)\n",
    "        out_df_dict[key] = pd.concat(dfs, ignore_index=False)\n",
    "\n",
    "    return out_df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- MC study\n",
    "# mc_file = \"/exp/sbnd/data/users/munjung/xsec/2025B/MCP_gump_new.df\"\n",
    "mc_file = \"/exp/sbnd/data/users/munjung/xsec/2025B/MC_test.df\"\n",
    "mc_split_df = pd.read_hdf(mc_file, key=\"split\")\n",
    "mc_n_split = get_n_split(mc_file)\n",
    "print(\"mc_n_split: %d\" %(mc_n_split))\n",
    "print_keys(mc_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_max_concat = 2\n",
    "\n",
    "mc_keys2load = ['evt', 'hdr', 'mcnuwgtslim']\n",
    "mc_dfs = load_dfs(mc_file, mc_keys2load)\n",
    "\n",
    "mc_evt_df = mc_dfs['evt']\n",
    "mc_hdr_df = mc_dfs['hdr']\n",
    "mc_nu_df = mc_dfs['mcnuwgtslim']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make MCstat uncertainty universes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MCstat_unc(evt_df, hdr_df, n_universes=100):\n",
    "    # Create a unique seed based on event metadata\n",
    "    # Using a hash function that's deterministic\n",
    "    meta_seeds = []\n",
    "    for i in tqdm(range(len(evt_df))):\n",
    "        this_hdr_df = hdr_df.loc[evt_df.reset_index(level=[2]).index[i]]\n",
    "        runno = this_hdr_df.run\n",
    "        subrunno = this_hdr_df.subrun\n",
    "        evtno = this_hdr_df.evt\n",
    "        slcid = mc_evt_df.loc[mc_evt_df.index[i]].slc.self\n",
    "        unique_seed = hash(f\"run_{runno}_subrun_{subrunno}_evt_{evtno}_slcid_{slcid}\") % (2**32)  # Ensure it's a 32-bit integer\n",
    "        if unique_seed in meta_seeds:\n",
    "            print(\"duplicate seed found\", unique_seed)\n",
    "            break\n",
    "        meta_seeds.append(unique_seed)\n",
    "\n",
    "    # make sure the seeds are unique!\n",
    "    assert len(meta_seeds) == len(set(meta_seeds))\n",
    "\n",
    "    # generate universes\n",
    "    n_universes = 100\n",
    "    MCstat_univ_events = np.zeros((n_universes, len(evt_df)))\n",
    "    poisson_mean = 1.0\n",
    "\n",
    "    # get Poisson weights and save to \"MCstat.univ_\"\n",
    "    # dummy df to hold the weights -- iterative inserting causes PerformanceWarning\n",
    "    mcstat_univ_cols = pd.MultiIndex.from_product(\n",
    "        [[\"MCstat\"], [f\"univ_{i}\" for i in range(n_universes)], [\"\"], [\"\"], [\"\"], [\"\"], [\"\"], [\"\"]],\n",
    "    )\n",
    "    mcstat_univ_wgt = pd.DataFrame(\n",
    "        1.0,\n",
    "        index=evt_df.index,\n",
    "        columns=mcstat_univ_cols,\n",
    "    )\n",
    "\n",
    "    for uidx in range(n_universes):\n",
    "        universe_seed = hash(f\"universe_{uidx}\") % (2**32)\n",
    "        \n",
    "        poisson_weights = []\n",
    "        for sidx, meta_seed in enumerate(meta_seeds):\n",
    "            # Combine universe seed with event seed for unique randomness -- per event, per universe\n",
    "            combined_seed = (universe_seed + meta_seed) % (2**32)\n",
    "            np.random.seed(combined_seed)\n",
    "            \n",
    "            poisson_val = np.random.poisson(poisson_mean)\n",
    "            poisson_weights.append(poisson_val)\n",
    "        \n",
    "        mcstat_univ_wgt[(\"MCstat\", \"univ_{}\".format(uidx), \"\", \"\", \"\", \"\", \"\", \"\")] = np.array(poisson_weights)\n",
    "        MCstat_univ_events[uidx, :] = np.array(poisson_weights)\n",
    "\n",
    "    evt_df = evt_df.join(mcstat_univ_wgt)\n",
    "    return evt_df, MCstat_univ_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_evt_df, MCstat_univ_events = get_MCstat_unc(mc_evt_df, mc_hdr_df, n_universes=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## total pot\n",
    "mc_tot_pot = mc_hdr_df['pot'].sum()\n",
    "print(\"mc_tot_pot: %.3e\" %(mc_tot_pot))\n",
    "\n",
    "target_pot = 1e20\n",
    "mc_pot_scale = target_pot / mc_tot_pot\n",
    "print(\"mc_pot_scale: %.3e\" %(mc_pot_scale))\n",
    "mc_pot_scale = 1.\n",
    "\n",
    "mc_evt_df[\"pot_weight\"] = mc_pot_scale * np.ones(len(mc_evt_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: z-dependence?\n",
    "# flux file, units: /m^2/10^6 POT \n",
    "# 50 MeV bins\n",
    "fluxfile = \"/exp/sbnd/data/users/munjung/flux/sbnd_original_flux.root\"\n",
    "flux = uproot.open(fluxfile)\n",
    "print(flux.keys())\n",
    "\n",
    "# numu flux\n",
    "numu_flux = flux[\"flux_sbnd_numu\"].to_numpy()\n",
    "bin_edges = numu_flux[1]\n",
    "flux_vals = numu_flux[0]\n",
    "\n",
    "plt.hist(bin_edges[:-1], bins=bin_edges, weights=flux_vals, histtype=\"step\")\n",
    "plt.xlabel(\"E [GeV]\")\n",
    "plt.ylabel(\"Flux [/m$^{2}$/10$^{6}$ POT]\")\n",
    "plt.title(\"SBND $\\\\nu_\\\\mu$ Flux\")\n",
    "plt.show()\n",
    "\n",
    "# get integrated flux\n",
    "integrated_flux = flux_vals.sum()\n",
    "integrated_flux /= 1e4 # to cm2\n",
    "INTEGRATED_FLUX = integrated_flux * mc_tot_pot / 1e6 # POT\n",
    "print(\"Integrated flux: %.3e\" % INTEGRATED_FLUX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RHO = 1.3836  #g/cm3, liquid Ar density\n",
    "N_A = 6.02214076e23 # Avogadroâ€™s number\n",
    "M_AR = 39.95 # g, molar mass of argon\n",
    "V_SBND = 380 * 380 * 440 # cm3, the active volume of the detector \n",
    "NTARGETS = RHO * V_SBND * N_A / M_AR\n",
    "print(\"# of targets: \", NTARGETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to 1 for event rates\n",
    "XSEC_UNIT = 1 / (INTEGRATED_FLUX * NTARGETS)\n",
    "\n",
    "# XSEC_UNIT = 1\n",
    "print(\"xsec unit: \", XSEC_UNIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up utils and selections according to target channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InFV(data): # cm\n",
    "    xmin = -190.\n",
    "    ymin = -190.\n",
    "    zmin = 10.\n",
    "    xmax = 190.\n",
    "    ymax =  190.\n",
    "    zmax =  450.\n",
    "    return (np.abs(data.x) > 10) & (np.abs(data.x) < 190) & (data.y > ymin) & (data.y < ymax) & (data.z > zmin) & (data.z < zmax)\n",
    "\n",
    "\n",
    "def IsNu(df):\n",
    "    return ~df.pdg.isna()\n",
    "\n",
    "\n",
    "def IsSignal(df): # definition                                                                                                                                                                                                                                                                         \n",
    "    is_fv = InFV(df.position)\n",
    "    is_1mu1p0pi = (df.nmu_27MeV == 1) & (df.npi_30MeV == 0) & (df.np_50MeV == 1) & (df.npi0 == 0) & (df.mu.genE < 1.2) # & (df.np_20MeV == 1) : add with stubs\n",
    "    return is_fv & is_1mu1p0pi\n",
    "\n",
    "\n",
    "def Is1muNp0pi(df): # definition                                                                                                                                                                                                                                                                         \n",
    "    is_fv = InFV(df.position)\n",
    "    is_1mu1p0pi = (df.nmu_27MeV == 1) & (df.npi_30MeV == 0) & (df.np_50MeV > 1) & (df.npi0 == 0) #& (df.mu.genE > 0.25) # & (df.np_20MeV == 1) : add with stubs\n",
    "    return is_fv & is_1mu1p0pi\n",
    "\n",
    "\n",
    "def Is1muNcpi(df): # definition                                                                                                                                                                                                                                                                         \n",
    "    is_fv = InFV(df.position)\n",
    "    is_1mu1p0pi = (df.nmu_27MeV == 1) & (df.npi_30MeV > 0) & (df.npi0 == 0) #& (df.mu.genE > 0.25) # & (df.np_20MeV == 1) : add with stubs\n",
    "    return is_fv & is_1mu1p0pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_int_category(df):\n",
    "    is_notnu = ~IsNu(df)\n",
    "    is_nu_outfv = IsNu(df) & ~InFV(df.position)\n",
    "    is_signal = IsSignal(df)\n",
    "    is_1muNp0pi = Is1muNp0pi(df)\n",
    "    is_1muNcpi = Is1muNcpi(df)\n",
    "    # assert there's no overlap between the categories\n",
    "    assert (is_1muNp0pi & is_1muNcpi).sum() == 0\n",
    "    assert (is_1muNp0pi & is_signal).sum() == 0\n",
    "    assert (is_1muNcpi & is_signal).sum() == 0\n",
    "    assert (is_1muNp0pi & is_nu_outfv).sum() == 0\n",
    "    assert (is_1muNcpi & is_nu_outfv).sum() == 0\n",
    "    assert (is_signal & is_nu_outfv).sum() == 0\n",
    "    is_other_nu_infv = IsNu(df) & InFV(df.position) & ~IsSignal(df) & ~Is1muNp0pi(df) & ~Is1muNcpi(df)\n",
    "\n",
    "    nuint_categ = pd.Series(8, index=df.index)\n",
    "    nuint_categ[is_notnu] = -1  # not nu\n",
    "    nuint_categ[is_nu_outfv] = 0  # nu out of FV\n",
    "    nuint_categ[is_signal] = 1    # nu in FV, signal\n",
    "    nuint_categ[is_1muNp0pi] = 2  # 1mu, 0cpi, Np, 0pi0\n",
    "    nuint_categ[is_1muNcpi] = 3  # 1mu, Ncpi, 0pi0\n",
    "    nuint_categ[is_other_nu_infv] = 4  # nu in FV, not signal\n",
    "\n",
    "    return nuint_categ\n",
    "\n",
    "\n",
    "# signal need to come first for below code to work\n",
    "mode_list = [1, 2, 3, 4, 0, -1]\n",
    "mode_labels = [\"Signal\", r\"$1\\mu N(>1)p 0\\pi^{\\pm}$\", r\"$1\\mu Ncpi$\", \"Other FV Nu\", \"Non FV Nu\", \"Not Nu\"]\n",
    "# colors = ['#d62728',  # Red            \n",
    "#           '#1f77b4',  # Blue\n",
    "#           '#ff7f0e',\n",
    "#           '#2ca02c',\n",
    "#           '#9467bd',\n",
    "#           '#7f7f7f']  # Gray\n",
    "\n",
    "colors = [\"mediumslateblue\",\n",
    "              \"darkslateblue\",\n",
    "              \"darkgreen\",\n",
    "              \"crimson\",\n",
    "              \"sienna\",\n",
    "              '#7f7f7f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ccqe selection\n",
    "\n",
    "# in FV\n",
    "# print(InFV(mc_evt_df.slc.vertex).value_counts())\n",
    "mc_evt_df = mc_evt_df[InFV(mc_evt_df.slc.vertex)]\n",
    "\n",
    "mc_evt_df = mc_evt_df[(mc_evt_df.slc.nu_score > 0.5)]\n",
    "\n",
    "# # mu length cut\n",
    "mc_evt_df = mc_evt_df[mc_evt_df.mu.pfp.trk.len > 50]\n",
    "\n",
    "# # mu containment cut\n",
    "mc_evt_df = mc_evt_df[mc_evt_df.mu.pfp.trk.is_contained == True]\n",
    "mc_evt_df = mc_evt_df[mc_evt_df.p.pfp.trk.is_contained == True]\n",
    "\n",
    "# # mu chi2 cut \n",
    "mc_evt_df = mc_evt_df[(mc_evt_df.mu.pfp.trk.chi2pid.I2.chi2_muon > 0) & (mc_evt_df.mu.pfp.trk.chi2pid.I2.chi2_muon < 25) & (mc_evt_df.mu.pfp.trk.chi2pid.I2.chi2_proton > 100)]\n",
    "\n",
    "# protons chi2 cut\n",
    "mc_evt_df = mc_evt_df[(mc_evt_df.p.pfp.trk.chi2pid.I2.chi2_proton > 0) & (mc_evt_df.p.pfp.trk.chi2pid.I2.chi2_proton < 90)]\n",
    "\n",
    "# 1p0pi\n",
    "twoprong_cut = (np.isnan(mc_evt_df.other_shw_length) & np.isnan(mc_evt_df.other_trk_length))\n",
    "mc_evt_df = mc_evt_df[twoprong_cut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify events into categories\n",
    "mc_evt_df.loc[:,'nuint_categ'] = get_int_category(mc_evt_df)\n",
    "mc_nu_df.loc[:,'nuint_categ'] = get_int_category(mc_nu_df)\n",
    "\n",
    "print(mc_evt_df.nuint_categ.value_counts())\n",
    "print(mc_nu_df.nuint_categ.value_counts()) # won't have -1 because nudf is all nu events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable to unfold\n",
    "\n",
    "class VariableConfig:\n",
    "    \"\"\"\n",
    "    A configurable class for setting up unfolding variable configurations.\n",
    "    Choose a configuration using one of the provided class methods,\n",
    "    or instantiate directly with custom parameters.\n",
    "    \"\"\"\n",
    "    def __init__(self, var_save_name, var_plot_name, var_unit, bins, var_evt_reco_col, var_evt_truth_col, var_nu_col):\n",
    "        self.var_save_name = var_save_name\n",
    "        self.var_plot_name = var_plot_name\n",
    "        self.var_unit = var_unit\n",
    "        unit_suffix = f\"~[{var_unit}]\" if len(var_unit) > 0 else \"\"\n",
    "        self.var_labels = [r\"$\\mathrm{\" + var_plot_name + unit_suffix + \"}$\", \n",
    "                           r\"$\\mathrm{\" + var_plot_name + \"^{reco.}\" + unit_suffix + \"}$\", \n",
    "                           r\"$\\mathrm{\" + var_plot_name + \"^{true}\" + unit_suffix + \"}$\"]\n",
    "        self.bins = bins\n",
    "        self.bin_centers = (bins[:-1] + bins[1:]) / 2.\n",
    "        self.var_evt_reco_col = var_evt_reco_col\n",
    "        self.var_evt_truth_col = var_evt_truth_col\n",
    "        self.var_nu_col = var_nu_col\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def muon_momentum(cls):\n",
    "        return cls(\n",
    "            var_save_name=\"muon-p\",\n",
    "            var_plot_name=\"P_\\mu\",\n",
    "            var_unit=\"GeV/c\",\n",
    "            bins=np.linspace(0.15, 1.2, 11),\n",
    "            var_evt_reco_col=('mu', 'pfp', 'trk', 'P', 'p_muon', '', '', ''),\n",
    "            var_evt_truth_col=('mu', 'pfp', 'trk', 'truth', 'p', 'totp', '', ''),\n",
    "            var_nu_col=('mu', 'totp', '')\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def muon_direction(cls):\n",
    "        return cls(\n",
    "            var_save_name=\"muon-dir_z\",\n",
    "            var_plot_name=\"cos(\\theta_\\mu)\",\n",
    "            var_unit=\"\",\n",
    "            bins=np.linspace(-1, 1, 6),\n",
    "            var_evt_reco_col=('mu', 'pfp', 'trk', 'dir', 'z', '', '', ''),\n",
    "            var_evt_truth_col=('mu', 'pfp', 'trk', 'truth', 'p', 'dir', 'z', ''),\n",
    "            var_nu_col=('mu', 'dir', 'z')\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def proton_momentum(cls):\n",
    "        return cls(\n",
    "            var_save_name=\"proton-p\",\n",
    "            var_plot_name=\"P_p\",\n",
    "            var_unit=\"GeV/c\",\n",
    "            bins=np.linspace(0.2, 2, 6),\n",
    "            var_evt_reco_col=('p', 'pfp', 'trk', 'P', 'p_proton', '', '', ''),\n",
    "            var_evt_truth_col=('p', 'pfp', 'trk', 'truth', 'p', 'totp', '', ''),\n",
    "            var_nu_col=('p', 'totp', '')\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def proton_direction(cls):\n",
    "        return cls(\n",
    "            var_save_name=\"proton-dir_z\",\n",
    "            var_plot_name=\"cos(\\theta_p)\",\n",
    "            var_unit=\"\",\n",
    "            bins=np.linspace(-1, 1, 6),\n",
    "            var_evt_reco_col=('p', 'pfp', 'trk', 'dir', 'z', '', '', ''),\n",
    "            var_evt_truth_col=('p', 'pfp', 'trk', 'truth', 'p', 'dir', 'z', ''),\n",
    "            var_nu_col=('p', 'dir', 'z')\n",
    "        )\n",
    "\n",
    "var_config = VariableConfig.muon_momentum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "genie_mode_list = [0, 10, 1, 2, 3]\n",
    "genie_mode_labels = [r'$\\nu_{\\mu}$ CC QE', r'$\\nu_{\\mu}$ CC MEC', r'$\\nu_{\\mu}$ CC RES', r'$\\nu_{\\mu}$ CC SIS/DIS', r'$\\nu_{\\mu}$ CC COH'] #, r'not $\\nu$']\n",
    "# [r\"non FV $\\nu$\", \"Cosmic\", r\"$\\nu$ NC\"] + \n",
    "genie_mode_colors = [\"#9b5580\", \"#390C1E\", \"#2c7c94\", \"#D88A3B\", \"#BFB17C\"] #, '#7f7f7f']\n",
    "# [\"sienna\", \"crimson\", \"darkgreen\"] + "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make dfs for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.clip is for including underflow events into the first bin and overflow events into the last bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total MC reco muon momentum: for fake data\n",
    "eps = 1e-8\n",
    "var_total_mc = mc_evt_df[var_config.var_evt_reco_col]\n",
    "var_total_mc = np.clip(var_total_mc, var_config.bins[0], var_config.bins[-1] - eps)\n",
    "weights_total_mc = mc_evt_df.loc[:, 'pot_weight']\n",
    "\n",
    "# --- all events, selected ---\n",
    "# mc_evt_df divided into topology modes for subtraction from data in future\n",
    "# first item in list is the signal topology\n",
    "mc_evt_df_divided = [mc_evt_df[mc_evt_df.nuint_categ == mode]for mode in mode_list]\n",
    "\n",
    "# Reco variable distribution for each 'nuint_categ' for stack plot and subtraction from the fake data\n",
    "var_per_nuint_categ_mc = [mc_evt_df[mc_evt_df.nuint_categ == mode][var_config.var_evt_reco_col]for mode in mode_list]\n",
    "var_per_nuint_categ_mc = [s.clip(var_config.bins[0], var_config.bins[-1] - eps) for s in var_per_nuint_categ_mc]\n",
    "weights_per_categ = [mc_evt_df.loc[mc_evt_df.nuint_categ == mode, 'pot_weight'] for mode in mode_list]\n",
    "\n",
    "# Reco variable distribution for each genie mode\n",
    "var_per_genie_mode_mc = [mc_evt_df[mc_evt_df.genie_mode == mode][var_config.var_evt_reco_col]for mode in genie_mode_list]\n",
    "var_per_genie_mode_mc = [s.clip(var_config.bins[0], var_config.bins[-1] - eps) for s in var_per_genie_mode_mc]\n",
    "weights_per_genie_mode = [mc_evt_df.loc[mc_evt_df.genie_mode == mode, 'pot_weight'] for mode in genie_mode_list]\n",
    "\n",
    "\n",
    "# --- signal events ---\n",
    "# selected, for response matrix\n",
    "# Signal event's reco muon momentum after the event selection\n",
    "var_signal_sel_reco = mc_evt_df[mc_evt_df.nuint_categ == 1][var_config.var_evt_reco_col]\n",
    "var_signal_sel_reco = np.clip(var_signal_sel_reco, var_config.bins[0], var_config.bins[-1] - eps)\n",
    "weight_signal = mc_evt_df.loc[mc_evt_df.nuint_categ == 1, 'pot_weight']\n",
    "\n",
    "# Signal event's true muon momentum after the event selection\n",
    "var_signal_sel_truth = mc_evt_df[mc_evt_df.nuint_categ == 1][var_config.var_evt_truth_col]\n",
    "var_signal_sel_truth = np.clip(var_signal_sel_truth, var_config.bins[0], var_config.bins[-1] - eps)\n",
    "weight_true_signal = mc_evt_df.loc[mc_evt_df.nuint_categ == 1, 'pot_weight']\n",
    "\n",
    "# total generated, for efficiency vector\n",
    "# Signal event's true muon momentum without event selection\n",
    "var_truth_signal = mc_nu_df[mc_nu_df.nuint_categ == 1][var_config.var_nu_col]\n",
    "var_truth_signal = np.clip(var_truth_signal, var_config.bins[0], var_config.bins[-1] - eps)\n",
    "weight_truth_signal = np.full_like(var_truth_signal, mc_pot_scale, dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw true (before event selection) and reco (after event selection) muon momentum distributions of signal events.\n",
    "Print entries for double check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nevts_signal_truth, _, _ = plt.hist(var_truth_signal, bins=var_config.bins, weights=weight_truth_signal, histtype=\"step\", label=\"True Signal\")\n",
    "nevts_signal_sel_reco, _, _ = plt.hist(var_signal_sel_reco, bins=var_config.bins, weights=weight_signal, histtype=\"step\", label=\"Reco Selected Signal\", color=\"k\")\n",
    "nevts_signal_sel_truth, _, _ = plt.hist(var_signal_sel_truth, bins=var_config.bins, weights=weight_signal, histtype=\"step\", label=\"True Selected Signal\")\n",
    "print(nevts_signal_truth)\n",
    "print(nevts_signal_sel_reco)\n",
    "print(nevts_signal_sel_truth)\n",
    "plt.legend()\n",
    "plt.ylabel(\"Events\")\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[0])\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-sel_event_rates.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_2d = var_config.bins# = [np.array([0.2, 2]), np.array([0.2, 2])] # commented out lines for 1 bin MC closure test\n",
    "\n",
    "save_fig_name = \"{}/{}-reco_vs_true\".format(save_fig_dir, var_config.var_save_name)\n",
    "reco_vs_true = get_smear_matrix(var_signal_sel_truth, var_signal_sel_reco, bins_2d, var_labels=var_config.var_labels,\n",
    "                                save_fig=save_fig, save_fig_name=save_fig_name)\n",
    "eff = get_eff(reco_vs_true, nevts_signal_truth)\n",
    "print(\"eff\")\n",
    "print(eff)\n",
    "\n",
    "save_fig_name = \"{}/{}-response_matrix\".format(save_fig_dir, var_config.var_save_name)\n",
    "Response = get_response_matrix(reco_vs_true, eff, var_config.bins, var_labels=var_config.var_labels,\n",
    "                               save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_covariance(cov_type, syst_name, n_univ, \n",
    "                   nevts_signal_sel_reco, var_signal_sel_truth, var_signal_sel_reco, bins, \n",
    "                   var_labels, save_fig=False, save_fig_name=None):\n",
    "\n",
    "    if cov_type == \"xsec\":\n",
    "        scale_factor = XSEC_UNIT\n",
    "        print(\"generating covariance for xsec, using scale factor: {}\".format(scale_factor))\n",
    "\n",
    "    elif cov_type == \"event\":\n",
    "        print(\"generating covariance for event rate\")\n",
    "        scale_factor = 1\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid cov_type: {}\".format(cov_type))\n",
    "\n",
    "    \n",
    "    signal_cv = nevts_signal_sel_reco * scale_factor # = Response @ true_signal\n",
    "\n",
    "    Covariance_Frac = np.zeros((len(signal_cv), len(signal_cv)))\n",
    "    Covariance = np.zeros((len(signal_cv), len(signal_cv)))\n",
    "\n",
    "    univ_events = []\n",
    "    for uidx in range(n_univ):\n",
    "        univ_col_evt = (syst_name, \"univ_{}\".format(uidx), \"\", \"\", \"\", \"\", \"\", \"\")\n",
    "        univ_col_mc = (syst_name, \"univ_{}\".format(uidx), \"\")\n",
    "\n",
    "        # ---- uncertainty on the signal rate ----\n",
    "        # GENIE syst need special treatment\n",
    "        # we don't want uncertainty on the xsec\n",
    "        # only consider its effect on the response matrix\n",
    "        if syst_name == \"GENIE\" and cov_type == \"xsec\":\n",
    "            true_signal_univ, _ = np.histogram(var_truth_signal, bins=var_config.bins, \n",
    "                                            weights=weight_truth_signal*mc_nu_df[mc_nu_df.nuint_categ == 1][univ_col_mc])\n",
    "            \n",
    "            # new response matrix for univ\n",
    "            reco_vs_true = get_smear_matrix(var_signal_sel_truth, var_signal_sel_reco, var_config.bins, \n",
    "                                            weights=mc_evt_df[mc_evt_df.nuint_categ == 1][univ_col_evt], plot=False)\n",
    "\n",
    "            eff = get_eff(reco_vs_true, true_signal_univ) \n",
    "\n",
    "            Response_univ = get_response_matrix(reco_vs_true, eff, bins, plot=False)\n",
    "            signal_univ = Response_univ @ nevts_signal_truth # note that we multiply the CV signal rate!\n",
    "\n",
    "        # for other systs, we just take the univ signal event rate\n",
    "        else:\n",
    "            signal_univ, _ = np.histogram(var_signal_sel_reco, bins=var_config.bins, \n",
    "                                             weights=mc_evt_df[mc_evt_df.nuint_categ == 1][univ_col_evt])\n",
    "\n",
    "        signal_univ = np.array(signal_univ) * scale_factor\n",
    "\n",
    "        # ---- uncertainty on the background rate ----\n",
    "        # loop over background categories\n",
    "        # + univ background - cv background\n",
    "        # note: cv background subtraction cancels out with the cv background subtraction for the cv event rate. \n",
    "        #       doing it anyways for the plot of universes on background subtracted event rate.\n",
    "        for this_mc_evt_df in mc_evt_df_divided[1:]:\n",
    "            weights = this_mc_evt_df[univ_col_evt].copy()\n",
    "            weights[np.isnan(weights)] = 1 ## IMPORTANT: make nan weights to 1. to ignore them\n",
    "            this_var = this_mc_evt_df[var_config.var_evt_reco_col]\n",
    "            this_var = np.clip(this_var, var_config.bins[0], var_config.bins[-1] - eps)\n",
    "            background_univ, _ = np.histogram(this_var, bins=var_config.bins, weights=weights)\n",
    "            background_cv, _ = np.histogram(this_var, bins=var_config.bins)\n",
    "            background_univ = np.array(background_univ) * scale_factor\n",
    "            background_cv = np.array(background_cv) * scale_factor\n",
    "            signal_univ += background_univ - background_cv\n",
    "\n",
    "        univ_events.append(signal_univ)\n",
    "        plt.hist(var_config.bin_centers, bins=var_config.bins, weights=signal_univ, histtype=\"step\", color=\"gray\")\n",
    "\n",
    "        # ---- covariance calculation ----\n",
    "        # I'm looping & calculating with the CV value for clarity, \n",
    "        # but techincally np.cov should also be fine under the assumption of gaussian universes that we're using\n",
    "        for i in range(len(signal_univ)):\n",
    "            for j in range(len(signal_univ)):\n",
    "                nom_i = signal_cv[i] \n",
    "                nom_j = signal_cv[j] \n",
    "\n",
    "                univ_i = signal_univ[i] \n",
    "                univ_j = signal_univ[j] \n",
    "\n",
    "                cov_entry = (univ_i - nom_i) * (univ_j - nom_j)\n",
    "                frac_cov_entry = ((univ_i - nom_i) / nom_i) * ( (univ_j - nom_j) / nom_j)\n",
    "\n",
    "                # TODO: this clipping exists in the uboone code, but I'm not sure why..?\n",
    "                # if cov_entry > 0:\n",
    "                #     this_cov = max( cov_entry, eps * scale_factor)\n",
    "                # else:\n",
    "                #     this_cov = min( cov_entry, eps * scale_factor)\n",
    "\n",
    "                # if frac_cov_entry > 0:\n",
    "                #     this_frac_cov = max( frac_cov_entry, eps * scale_factor)\n",
    "                # else:\n",
    "                #     this_frac_cov = min( frac_cov_entry, eps * scale_factor)\n",
    "\n",
    "                Covariance[i, j] += cov_entry\n",
    "                Covariance_Frac[i, j] += frac_cov_entry\n",
    "\n",
    "    plt.hist(var_config.bin_centers, bins=var_config.bins, weights=signal_cv, histtype=\"step\", color=\"black\", label=\"nominal_event\")\n",
    "\n",
    "    plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "    plt.xlabel(var_config.var_labels[0])\n",
    "    plt.ylabel(var_config.var_labels[1])\n",
    "    plt.title(syst_name)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    Covariance = Covariance / n_univ\n",
    "    Covariance_Frac = Covariance_Frac / n_univ\n",
    "    Correlation = np.zeros_like(Covariance)\n",
    "    for i in range(len(signal_cv)):\n",
    "        for j in range(len(signal_cv)):\n",
    "            Correlation[i, j] = Covariance[i, j] / (np.sqrt(Covariance[i, i]) * np.sqrt(Covariance[j, j]))\n",
    "\n",
    "    if save_fig:\n",
    "        plt.savefig(\"{}.pdf\".format(save_fig_name), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    return {\"Covariance_Frac\": Covariance_Frac, \n",
    "            \"Covariance\": Covariance,\n",
    "            \"Correlation\": Correlation,\n",
    "            \"cv_events\": signal_cv,\n",
    "            \"univ_events\": univ_events,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretty heatmap plotter\n",
    "\n",
    "unif_bin = np.linspace(0., float(len(var_config.bins) - 1), len(var_config.bins))\n",
    "extent = [unif_bin[0], unif_bin[-1], unif_bin[0], unif_bin[-1]]\n",
    "\n",
    "x_edges = np.array(var_config.bins)\n",
    "y_edges = np.array(var_config.bins)\n",
    "x_tick_positions = (unif_bin[:-1] + unif_bin[1:]) / 2\n",
    "y_tick_positions = (unif_bin[:-1] + unif_bin[1:]) / 2\n",
    "\n",
    "x_labels = bin_range_labels(x_edges)\n",
    "y_labels = bin_range_labels(y_edges)\n",
    "\n",
    "def plot_heatmap(matrix, title, plot_labels=var_config.var_labels, save_fig=False, save_fig_name=None):\n",
    "    plt.imshow(matrix, extent=extent, origin=\"lower\")\n",
    "    plt.colorbar()\n",
    "    plt.xticks(x_tick_positions, x_labels, rotation=45, ha=\"right\")\n",
    "    plt.yticks(y_tick_positions, y_labels)\n",
    "    plt.xlabel(plot_labels[0])\n",
    "    plt.ylabel(plot_labels[1])\n",
    "    for i in range(matrix.shape[0]):      # rows (y)\n",
    "        for j in range(matrix.shape[1]):  # columns (x)\n",
    "            value = matrix[i, j]\n",
    "            if not np.isnan(value):  # skip NaNs\n",
    "                plt.text(\n",
    "                    j + 0.5, i + 0.5,\n",
    "                    f\"{value:.2f}\",\n",
    "                    ha=\"center\", va=\"center\",   \n",
    "                    color=get_text_color(value),\n",
    "                    fontsize=10\n",
    "                )\n",
    "    plt.title(title)\n",
    "    if save_fig:\n",
    "        plt.savefig(\"{}.pdf\".format(save_fig_name), bbox_inches='tight')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MC Stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the average of universes' weights is ~ CV value\n",
    "univ_avg = mc_evt_df.MCstat.mean(axis=1)\n",
    "fig, ax = plt.subplots(2,1, figsize=(6, 6), sharex=True, gridspec_kw={'height_ratios': [2, 1]})\n",
    "cv_events, _, _ = ax[0].hist(mc_evt_df[var_config.var_evt_reco_col], bins=var_config.bins, histtype=\"step\", color=\"black\", label=\"nominal_event\")\n",
    "univ_avg_events, _, _ = ax[0].hist(mc_evt_df[var_config.var_evt_reco_col], bins=var_config.bins, weights=univ_avg, histtype=\"step\", color=\"red\", label=\"univ_avg\")\n",
    "ax[0].set_xlim(var_config.bins[0], var_config.bins[-1])\n",
    "ax[0].set_ylabel(\"Events\")\n",
    "ax[0].legend()\n",
    "\n",
    "bin_centers = (var_config.bins[1:] + var_config.bins[:-1]) / 2\n",
    "ratio = univ_avg_events/cv_events\n",
    "ax[1].hist(bin_centers, bins=var_config.bins, weights=ratio, histtype=\"step\", color=\"black\")\n",
    "ax[1].set_xlim(var_config.bins[0], var_config.bins[-1])\n",
    "ax[1].set_xlabel(var_config.var_labels[0])\n",
    "ax[1].set_ylabel(\"univ_avg/CV\")\n",
    "ax[1].set_xlabel(var_config.var_labels[0])\n",
    "ax[1].set_ylim(0.9, 1.1)\n",
    "\n",
    "tolerance = 0.05\n",
    "if np.all(np.abs(ratio - 1) < tolerance):\n",
    "    print(\"The average of universes' weights is within the tolerance of the CV value\")\n",
    "else:\n",
    "    print(\"The average of universes' weights is not within the tolerance of the CV value\")\n",
    "\n",
    "for uidx in range(100):\n",
    "    # print(uidx)\n",
    "    plt.hist(mc_evt_df[var_config.var_evt_reco_col], bins=var_config.bins, weights=mc_evt_df[\"MCstat\"][f\"univ_{uidx}\"], histtype=\"step\", color=\"gray\")\n",
    "\n",
    "plt.hist(mc_evt_df[var_config.var_evt_reco_col], bins=var_config.bins, histtype=\"step\", color=\"black\", label=\"nominal_event\")\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_type = \"xsec\"\n",
    "syst_name = \"MCstat\"\n",
    "n_univ = 100\n",
    "labels = [var_config.var_labels[1], \"Flux Integrated Event Rate\"]\n",
    "\n",
    "save_fig_name = \"{}/{}-{}-mcstat_univ_events\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "ret_mcstat = get_covariance(cov_type, syst_name, n_univ, \n",
    "                            nevts_signal_sel_reco, var_signal_sel_truth, var_signal_sel_reco, var_config.bins, \n",
    "                            labels, save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sign of fractional covariance is different from the other two?\n",
    "save_fig_name = \"{}/{}-{}-mcstat_covariance\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "plot_heatmap(ret_mcstat[\"Covariance\"], \"Covariance - mcstat\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)\n",
    "save_fig_name = \"{}/{}-{}-mcstat_covariance_frac\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "plot_heatmap(ret_mcstat[\"Covariance_Frac\"], \"Fractional Covariance - mcstat\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)\n",
    "save_fig_name = \"{}/{}-{}-mcstat_correlation\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "plot_heatmap(ret_mcstat[\"Correlation\"], \"Correlation - mcstat\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_type = \"xsec\"\n",
    "syst_name = \"Flux\"\n",
    "n_univ = 1000\n",
    "\n",
    "labels = [var_config.var_labels[1], \"Flux Integrated Event Rate\"]\n",
    "\n",
    "save_fig_name = \"{}/{}-{}-flux_univ_events\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "ret_flux = get_covariance(cov_type, syst_name, n_univ, \n",
    "                          nevts_signal_sel_reco, var_signal_sel_truth, var_signal_sel_reco, var_config.bins, \n",
    "                          labels, save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig_name = \"{}/{}-{}-flux_covariance\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "plot_heatmap(ret_flux[\"Covariance\"], \"Covariance - Flux\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)\n",
    "save_fig_name = \"{}/{}-{}-flux_covariance_frac\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "plot_heatmap(ret_flux[\"Covariance_Frac\"], \"Fractional Covariance - Flux\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)\n",
    "save_fig_name = \"{}/{}-{}-flux_correlation\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "plot_heatmap(ret_flux[\"Correlation\"], \"Correlation - Flux\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syst_type = \"xsec\"\n",
    "syst_name = \"GENIE\"\n",
    "n_univ = 100\n",
    "\n",
    "labels = [var_config.var_labels[1], \"Flux Integrated Event Rate\"]\n",
    "\n",
    "save_fig_name = \"{}/{}-{}-genie_univ_events\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "ret_genie = get_covariance(cov_type, syst_name, n_univ, \n",
    "                          nevts_signal_sel_reco, var_signal_sel_truth, var_signal_sel_reco, var_config.bins, \n",
    "                          labels, save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig_name = \"{}/{}-{}-genie_covariance\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "plot_heatmap(ret_genie[\"Covariance\"], \"Covariance - GENIE\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)\n",
    "save_fig_name = \"{}/{}-{}-genie_covariance_frac\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "plot_heatmap(ret_genie[\"Covariance_Frac\"], \"Fractional Covariance - GENIE\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)\n",
    "save_fig_name = \"{}/{}-{}-genie_correlation\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "plot_heatmap(ret_genie[\"Correlation\"], \"Correlation - GENIE\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add fractional covariance of all systs, then multiply by the CV value to get the covariance\n",
    "Total_Covariance_Frac = ret_flux[\"Covariance_Frac\"] + ret_genie[\"Covariance_Frac\"] + ret_mcstat[\"Covariance_Frac\"]\n",
    "\n",
    "Total_Covariance = np.zeros_like(Total_Covariance_Frac)\n",
    "for i in range(len(var_config.bins)-1):\n",
    "    for j in range(len(var_config.bins)-1):\n",
    "        Total_Covariance[i, j] = Total_Covariance_Frac[i, j] * (nevts_signal_sel_reco[i] * nevts_signal_sel_reco[j]) * XSEC_UNIT**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_mcstat[\"Covariance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig_name = \"{}/{}-{}-total_covariance_frac\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "plot_heatmap(Total_Covariance_Frac, \"Total Fractional Covariance\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fractional uncertainty\n",
    "frac_uncert_flux = np.sqrt(np.diag(ret_flux[\"Covariance_Frac\"]))\n",
    "frac_uncert_genie = np.sqrt(np.diag(ret_genie[\"Covariance_Frac\"]))\n",
    "frac_uncert_mcstat = np.sqrt(np.diag(ret_mcstat[\"Covariance_Frac\"]))\n",
    "frac_uncert_total = np.sqrt(np.diag(Total_Covariance_Frac))\n",
    "\n",
    "plt.hist(var_config.bin_centers, bins=var_config.bins, weights=frac_uncert_flux*1e2, histtype=\"step\", color=\"C0\", label=\"Flux\")\n",
    "plt.hist(var_config.bin_centers, bins=var_config.bins, weights=frac_uncert_genie*1e2, histtype=\"step\", color=\"C1\", label=\"GENIE\")\n",
    "plt.hist(var_config.bin_centers, bins=var_config.bins, weights=frac_uncert_mcstat*1e2, histtype=\"step\", color=\"C2\", label=\"MCstat\")\n",
    "plt.hist(var_config.bin_centers, bins=var_config.bins, weights=frac_uncert_total*1e2, histtype=\"step\", color=\"k\", label=\"Total\")\n",
    "\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[0])\n",
    "plt.ylabel(\"Uncertainty [%]\")\n",
    "plt.legend()\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-uncertainty_breakdown.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Singal distribution with error bars from diagonal components of covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute bin centers for error bars\n",
    "frac_uncert = np.sqrt(np.diag(Total_Covariance_Frac))\n",
    "plt.errorbar(bin_centers, nevts_signal_sel_reco*XSEC_UNIT, yerr=frac_uncert*nevts_signal_sel_reco*XSEC_UNIT, fmt='o', color='black', label='Subtracted (syst. error)', capsize=3)\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[0])\n",
    "plt.ylabel(\"Events\")\n",
    "plt.legend()\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-bkg_subtracted_event_rates.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unfolding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closure test \n",
    "- use MC signal as fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect topology breakdown\n",
    "plt.figure(figsize=(8, 6))\n",
    "mc_stack, _, _ = plt.hist(var_per_nuint_categ_mc,\n",
    "                            bins=var_config.bins,\n",
    "                            weights=weights_per_categ,\n",
    "                            stacked=True,\n",
    "                            color=colors,\n",
    "                            label=mode_labels,\n",
    "                            edgecolor='none',\n",
    "                            linewidth=0,\n",
    "                            density=False,\n",
    "                            histtype='stepfilled')\n",
    "\n",
    "totmc, bin_edges = np.histogram(var_total_mc, bins=var_config.bins, weights=weights_total_mc)\n",
    "bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "# use MC as fake data for closure test\n",
    "fake_data = totmc\n",
    "fake_data_err = np.sqrt(totmc)\n",
    "# plt.step(bin_edges[:-1], fake_data, where='post', label=\"Data\")  # line\n",
    "plt.errorbar(bin_centers, fake_data, yerr=fake_data_err, fmt='o', color='black')  # error bars\n",
    "\n",
    "accum_sum = [np.sum(data) for data in mc_stack]\n",
    "accum_sum = [0.] + accum_sum\n",
    "total_sum = accum_sum[-1]\n",
    "individual_sums = [accum_sum[i + 1] - accum_sum[i] for i in range(len(accum_sum) - 1)]\n",
    "fractions = [(count / total_sum) * 100 for count in individual_sums]\n",
    "legend_labels = [f\"{label} ({frac:.1f}%)\" for label, frac in zip(mode_labels[::-1], fractions[::-1])]\n",
    "legend_labels.append(\"Fake Data\")\n",
    "plt.legend(legend_labels, loc='upper left', fontsize=10, frameon=False, ncol=3, bbox_to_anchor=(0.05, 0.98))\n",
    "\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[1])\n",
    "plt.ylim(0., 1.3 * fake_data.max())\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-topology_breakdown.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect GENIE mode breakdown\n",
    "plt.figure(figsize=(8, 6))\n",
    "mc_stack, _, _ = plt.hist(var_per_genie_mode_mc,\n",
    "                            bins=var_config.bins,\n",
    "                            weights=weights_per_genie_mode,\n",
    "                            stacked=True,\n",
    "                            color=genie_mode_colors,\n",
    "                            label=genie_mode_labels,\n",
    "                            edgecolor='none',\n",
    "                            linewidth=0,\n",
    "                            density=False,\n",
    "                            histtype='stepfilled')\n",
    "\n",
    "totmc, bin_edges = np.histogram(var_total_mc, bins=var_config.bins, weights=weights_total_mc)\n",
    "bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "# use MC as fake data for closure test\n",
    "fake_data = totmc\n",
    "fake_data_err = np.sqrt(totmc)\n",
    "# plt.step(bin_edges[:-1], fake_data, where='post', label=\"Data\")  # line\n",
    "plt.errorbar(bin_centers, fake_data, yerr=fake_data_err, fmt='o', color='black')  # error bars\n",
    "\n",
    "accum_sum = [np.sum(data) for data in mc_stack]\n",
    "accum_sum = [0.] + accum_sum\n",
    "total_sum = accum_sum[-1]\n",
    "individual_sums = [accum_sum[i + 1] - accum_sum[i] for i in range(len(accum_sum) - 1)]\n",
    "fractions = [(count / total_sum) * 100 for count in individual_sums]\n",
    "legend_labels = [f\"{label} ({frac:.1f}%)\" for label, frac in zip(genie_mode_labels[::-1], fractions[::-1])]\n",
    "legend_labels.append(\"Fake Data\")\n",
    "plt.legend(legend_labels, loc='upper left', fontsize=10, frameon=False, ncol=3, bbox_to_anchor=(0.05, 0.98))\n",
    "\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[1])\n",
    "plt.ylim(0., 1.3 * fake_data.max())\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-genie_mode_breakdown.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# closure test -- just use MC stat uncertainty\n",
    "C_type = 2\n",
    "Norm_type = 0.5\n",
    "Measured = nevts_signal_sel_reco * XSEC_UNIT # = fake_data - fake_background\n",
    "Model = nevts_signal_truth * XSEC_UNIT\n",
    "Covariance = ret_mcstat[\"Covariance\"]\n",
    "# Covariance = ret_flux[\"Covariance\"]\n",
    "unfold = WienerSVD(Response, Model, Measured, Covariance, C_type, Norm_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfold.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfold['unfold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfold['UnfoldCov']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2(data, model, cov):\n",
    "    return (data - model) @ np.linalg.inv(cov) @ (data - model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfold['unfold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfold['AddSmear'] @ nevts_signal_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unfold = unfold['unfold']\n",
    "UnfoldCov = unfold['UnfoldCov']\n",
    "Unfold_uncert = np.sqrt(np.diag(UnfoldCov))\n",
    "\n",
    "step_handle, = plt.step(bin_edges, np.append(Unfold, Unfold[-1]), where='post', label='Unfolded', color='black')\n",
    "bar_handle = plt.bar(\n",
    "    bin_centers,\n",
    "    2*Unfold_uncert,\n",
    "    width=(bin_edges[1] - bin_edges[0]) * 1.,\n",
    "    bottom=Unfold - Unfold_uncert,\n",
    "    color='gray',\n",
    "    alpha=0.5,\n",
    "    linewidth=0,\n",
    "    label='Unfolded Stat. error (box)'\n",
    ")\n",
    "reco_handle, = plt.plot(bin_centers, Measured, 'o', label='Reco. signal')\n",
    "Model_smear = unfold['AddSmear'] @ Model\n",
    "true_handle, = plt.plot(bin_centers, Model_smear, 'o', label='$A_c \\\\times$ True signal')\n",
    "\n",
    "# chi2_val = chi2(Unfold, Model_smear, UnfoldCov)\n",
    "# plt.text(0.95, 0.50, f\"$ \\\\chi^2 = $ {chi2_val:.2f}\", ha='right', va='center', \n",
    "#          transform=plt.gca().transAxes, fontsize=12)\n",
    "\n",
    "# Custom order for legend\n",
    "handles = [step_handle, bar_handle, reco_handle, true_handle]\n",
    "labels = [\n",
    "    'Unfolded',\n",
    "    'Unfolded error',\n",
    "    'Reco. signal',\n",
    "    '$A_c \\\\times$True signal'\n",
    "]\n",
    "\n",
    "plt.legend(handles, labels)\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[0])\n",
    "# plt.ylim(0., 5000.)\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-unfolded_event_rates.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig_name = \"{}/{}-{}-add_smear\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "plot_labels = [var_config.var_labels[2], var_config.var_labels[1]]\n",
    "plot_heatmap(unfold[\"AddSmear\"], \"$A_c$\", plot_labels=plot_labels,\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fake Data Tests\n",
    "\n",
    "- use alternate MC as fake data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MEC scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "mec_scale = 0.5\n",
    "weights_fake_data = np.ones(len(var_total_mc))\n",
    "weights_fake_data[mc_evt_df.genie_mode == 10] = mec_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "mc_stack, _, _ = plt.hist(var_per_nuint_categ_mc,\n",
    "                            bins=var_config.bins,\n",
    "                            weights=weights_per_categ,\n",
    "                            stacked=True,\n",
    "                            color=colors,\n",
    "                            label=mode_labels,\n",
    "                            edgecolor='none',\n",
    "                            linewidth=0,\n",
    "                            density=False,\n",
    "                            histtype='stepfilled')\n",
    "totmc, bin_edges = np.histogram(var_total_mc, bins=var_config.bins, weights=weights_total_mc * weights_fake_data)\n",
    "bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "# use MC as fake data for closure test\n",
    "fake_data = totmc\n",
    "fake_data_err = np.sqrt(totmc)\n",
    "plt.errorbar(bin_centers, fake_data, yerr=fake_data_err, fmt='o', color='black')  # error bars\n",
    "\n",
    "background_cv = mc_stack[-1] - mc_stack[0]\n",
    "# plt.hist(bin_centers, weights=fake_data - background_cv, bins=var_config.bins, histtype=\"step\", color=\"k\", label=\"Background\")\n",
    "\n",
    "accum_sum = [np.sum(data) for data in mc_stack]\n",
    "accum_sum = [0.] + accum_sum\n",
    "total_sum = accum_sum[-1]\n",
    "individual_sums = [accum_sum[i + 1] - accum_sum[i] for i in range(len(accum_sum) - 1)]\n",
    "fractions = [(count / total_sum) * 100 for count in individual_sums]\n",
    "legend_labels = [f\"{label} ({frac:.1f}%)\" for label, frac in zip(mode_labels[::-1], fractions[::-1])]\n",
    "legend_labels.append(\"Fake Data (MEC x{})\".format(mec_scale))\n",
    "plt.legend(legend_labels, loc='upper left', fontsize=10, frameon=False, ncol=3, bbox_to_anchor=(0.05, 0.98))\n",
    "\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[1])\n",
    "plt.ylim(0., 1.3 * fake_data.max())\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-topology_breakdown.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect GENIE mode breakdown\n",
    "plt.figure(figsize=(8, 6))\n",
    "mc_stack, _, _ = plt.hist(var_per_genie_mode_mc,\n",
    "                            bins=var_config.bins,\n",
    "                            weights=weights_per_genie_mode,\n",
    "                            stacked=True,\n",
    "                            color=genie_mode_colors,\n",
    "                            label=genie_mode_labels,\n",
    "                            edgecolor='none',\n",
    "                            linewidth=0,\n",
    "                            density=False,\n",
    "                            histtype='stepfilled')\n",
    "\n",
    "totmc, bin_edges = np.histogram(var_total_mc, bins=var_config.bins, weights=weights_total_mc * weights_fake_data)\n",
    "bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "# use MC as fake data for closure test\n",
    "fake_data = totmc\n",
    "fake_data_err = np.sqrt(totmc)\n",
    "# plt.step(bin_edges[:-1], fake_data, where='post', label=\"Data\")  # line\n",
    "plt.errorbar(bin_centers, fake_data, yerr=fake_data_err, fmt='o', color='black')  # error bars\n",
    "\n",
    "accum_sum = [np.sum(data) for data in mc_stack]\n",
    "accum_sum = [0.] + accum_sum\n",
    "total_sum = accum_sum[-1]\n",
    "individual_sums = [accum_sum[i + 1] - accum_sum[i] for i in range(len(accum_sum) - 1)]\n",
    "fractions = [(count / total_sum) * 100 for count in individual_sums]\n",
    "legend_labels = [f\"{label} ({frac:.1f}%)\" for label, frac in zip(genie_mode_labels[::-1], fractions[::-1])]\n",
    "legend_labels.append(\"Fake Data (MEC x{})\".format(mec_scale))\n",
    "plt.legend(legend_labels, loc='upper left', fontsize=10, frameon=False, ncol=3, bbox_to_anchor=(0.05, 0.98))\n",
    "\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[1])\n",
    "plt.ylim(0., 1.3 * fake_data.max())\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-genie_mode_breakdown.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake data test -- MC stat + xsec cov\n",
    "C_type = 2\n",
    "Norm_type = 0.5\n",
    "Measured = fake_data * XSEC_UNIT - background_cv * XSEC_UNIT\n",
    "Model = nevts_signal_truth * XSEC_UNIT\n",
    "\n",
    "# use MC stat and xsec cov\n",
    "Covariance_Frac = ret_genie[\"Covariance_Frac\"] + ret_mcstat[\"Covariance_Frac\"]\n",
    "\n",
    "Covariance = np.zeros_like(Covariance_Frac)\n",
    "for i in range(len(var_config.bins)-1):\n",
    "    for j in range(len(var_config.bins)-1):\n",
    "        Covariance[i, j] = Covariance_Frac[i, j] * (nevts_signal_sel_reco[i] * nevts_signal_sel_reco[j]) * XSEC_UNIT**2\n",
    "\n",
    "unfold = WienerSVD(Response, Model, Measured, Covariance, C_type, Norm_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true cross section for alt MC used asfake data\n",
    "var_fakedata_signal_truth = mc_nu_df[mc_nu_df.nuint_categ == 1][var_config.var_nu_col]\n",
    "var_fakedata_signal_truth = np.clip(var_fakedata_signal_truth, var_config.bins[0], var_config.bins[-1] - eps)\n",
    "weight_fakedata_signal_truth = np.ones(len(var_fakedata_signal_truth))\n",
    "nevts_fakedata_signal_truth, _, _ = plt.hist(var_fakedata_signal_truth, bins=var_config.bins, weights=weight_fakedata_signal_truth, histtype=\"step\", label=\"True Signal\")\n",
    "weight_fakedata_signal_truth[mc_nu_df[mc_nu_df.nuint_categ == 1].genie_mode == 10] = mec_scale\n",
    "nevts_fakedata_signal_truth, _, _ = plt.hist(var_fakedata_signal_truth, bins=var_config.bins, weights=weight_fakedata_signal_truth, histtype=\"step\", label=\"MEC x2 True Signal\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "Unfold = unfold['unfold']\n",
    "UnfoldCov = unfold['UnfoldCov']\n",
    "Unfold_uncert = np.sqrt(np.diag(UnfoldCov))\n",
    "\n",
    "step_handle, = plt.step(bin_edges, np.append(Unfold, Unfold[-1]), where='post', label='Unfolded', color='black')\n",
    "bar_handle = plt.bar(\n",
    "    bin_centers,\n",
    "    2*Unfold_uncert,\n",
    "    width=(bin_edges[1] - bin_edges[0]) * 1.,\n",
    "    bottom=Unfold - Unfold_uncert,\n",
    "    color='gray',\n",
    "    alpha=0.5,\n",
    "    linewidth=0,\n",
    "    label='Unfolded Stat. error (box)'\n",
    ")\n",
    "reco_handle, = plt.plot(bin_centers, Measured, 'o', label='Reco. signal')\n",
    "Model_smear = unfold['AddSmear'] @ Model\n",
    "true_handle, = plt.plot(bin_centers, Model_smear, 'o', label='$A_c \\\\times$ True signal')\n",
    "Fakedata_Model_smear = unfold['AddSmear'] @ nevts_fakedata_signal_truth*XSEC_UNIT\n",
    "fake_true_handle, = plt.plot(bin_centers, Fakedata_Model_smear, 'o', label='Fake Data')\n",
    "\n",
    "chi2_val = chi2(Unfold, Model_smear, UnfoldCov)\n",
    "chi2_val_fakedata = chi2(Unfold, Fakedata_Model_smear, UnfoldCov)\n",
    "# plt.text(0.95, 0.50, f\"$ \\\\chi^2 = $ {chi2_val:.2f}\", ha='right', va='center', \n",
    "#          transform=plt.gca().transAxes, fontsize=12)\n",
    "\n",
    "# Custom order for legend\n",
    "handles = [step_handle, bar_handle, reco_handle, true_handle, fake_true_handle]\n",
    "labels = [\n",
    "    'Unfolded',\n",
    "    'Unfolded error',\n",
    "    'Reco. signal',\n",
    "    '$A_c \\\\times$Nominal Truth ($\\\\chi^2 = {:.2f}/{}$)'.format(chi2_val, len(var_config.bins)-1),\n",
    "    '$A_c \\\\times$ MECx{} Truth ($\\\\chi^2 = {:.2f}/{}$)'.format(mec_scale, chi2_val_fakedata, len(var_config.bins)-1),\n",
    "]\n",
    "\n",
    "plt.legend(handles, labels, fontsize=12)\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[0])\n",
    "# plt.ylim(0., 5000.)\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-unfolded_event_rates.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig_name = \"{}/{}-{}-add_smear\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "plot_labels = [var_config.var_labels[2], var_config.var_labels[1]]\n",
    "plot_heatmap(unfold[\"AddSmear\"], \"$A_c$\", plot_labels=plot_labels,\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QE scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "qe_scale = 1.2\n",
    "weights_fake_data = np.ones(len(var_total_mc))\n",
    "weights_fake_data[mc_evt_df.genie_mode == 0] = qe_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "mc_stack, _, _ = plt.hist(var_per_nuint_categ_mc,\n",
    "                            bins=var_config.bins,\n",
    "                            weights=weights_per_categ,\n",
    "                            stacked=True,\n",
    "                            color=colors,\n",
    "                            label=mode_labels,\n",
    "                            edgecolor='none',\n",
    "                            linewidth=0,\n",
    "                            density=False,\n",
    "                            histtype='stepfilled')\n",
    "totmc, bin_edges = np.histogram(var_total_mc, bins=var_config.bins, weights=weights_total_mc * weights_fake_data)\n",
    "bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "# use MC as fake data for closure test\n",
    "fake_data = totmc\n",
    "fake_data_err = np.sqrt(totmc)\n",
    "plt.errorbar(bin_centers, fake_data, yerr=fake_data_err, fmt='o', color='black')  # error bars\n",
    "\n",
    "background_cv = mc_stack[-1] - mc_stack[0]\n",
    "# plt.hist(bin_centers, weights=fake_data - background_cv, bins=var_config.bins, histtype=\"step\", color=\"k\", label=\"Background\")\n",
    "\n",
    "accum_sum = [np.sum(data) for data in mc_stack]\n",
    "accum_sum = [0.] + accum_sum\n",
    "total_sum = accum_sum[-1]\n",
    "individual_sums = [accum_sum[i + 1] - accum_sum[i] for i in range(len(accum_sum) - 1)]\n",
    "fractions = [(count / total_sum) * 100 for count in individual_sums]\n",
    "legend_labels = [f\"{label} ({frac:.1f}%)\" for label, frac in zip(mode_labels[::-1], fractions[::-1])]\n",
    "legend_labels.append(\"Fake Data (QE x{})\".format(qe_scale))\n",
    "plt.legend(legend_labels, loc='upper left', fontsize=10, frameon=False, ncol=3, bbox_to_anchor=(0.05, 0.98))\n",
    "\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[1])\n",
    "plt.ylim(0., 1.3 * fake_data.max())\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-topology_breakdown.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect GENIE mode breakdown\n",
    "plt.figure(figsize=(8, 6))\n",
    "mc_stack, _, _ = plt.hist(var_per_genie_mode_mc,\n",
    "                            bins=var_config.bins,\n",
    "                            weights=weights_per_genie_mode,\n",
    "                            stacked=True,\n",
    "                            color=genie_mode_colors,\n",
    "                            label=genie_mode_labels,\n",
    "                            edgecolor='none',\n",
    "                            linewidth=0,\n",
    "                            density=False,\n",
    "                            histtype='stepfilled')\n",
    "\n",
    "totmc, bin_edges = np.histogram(var_total_mc, bins=var_config.bins, weights=weights_total_mc * weights_fake_data)\n",
    "bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "# use MC as fake data for closure test\n",
    "fake_data = totmc\n",
    "fake_data_err = np.sqrt(totmc)\n",
    "# plt.step(bin_edges[:-1], fake_data, where='post', label=\"Data\")  # line\n",
    "plt.errorbar(bin_centers, fake_data, yerr=fake_data_err, fmt='o', color='black')  # error bars\n",
    "\n",
    "accum_sum = [np.sum(data) for data in mc_stack]\n",
    "accum_sum = [0.] + accum_sum\n",
    "total_sum = accum_sum[-1]\n",
    "individual_sums = [accum_sum[i + 1] - accum_sum[i] for i in range(len(accum_sum) - 1)]\n",
    "fractions = [(count / total_sum) * 100 for count in individual_sums]\n",
    "legend_labels = [f\"{label} ({frac:.1f}%)\" for label, frac in zip(genie_mode_labels[::-1], fractions[::-1])]\n",
    "legend_labels.append(\"Fake Data (QE x{})\".format(qe_scale))\n",
    "plt.legend(legend_labels, loc='upper left', fontsize=10, frameon=False, ncol=3, bbox_to_anchor=(0.05, 0.98))\n",
    "\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[1])\n",
    "plt.ylim(0., 1.3 * fake_data.max())\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-genie_mode_breakdown.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake data test -- MC stat + xsec cov\n",
    "C_type = 2\n",
    "Norm_type = 0.5\n",
    "Measured = fake_data * XSEC_UNIT - background_cv * XSEC_UNIT\n",
    "Model = nevts_signal_truth * XSEC_UNIT\n",
    "\n",
    "# use MC stat and xsec cov\n",
    "Covariance_Frac = ret_genie[\"Covariance_Frac\"] + ret_mcstat[\"Covariance_Frac\"]\n",
    "\n",
    "Covariance = np.zeros_like(Covariance_Frac)\n",
    "for i in range(len(var_config.bins)-1):\n",
    "    for j in range(len(var_config.bins)-1):\n",
    "        Covariance[i, j] = Covariance_Frac[i, j] * (nevts_signal_sel_reco[i] * nevts_signal_sel_reco[j]) * XSEC_UNIT**2\n",
    "\n",
    "unfold = WienerSVD(Response, Model, Measured, Covariance, C_type, Norm_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true cross section for alt MC used asfake data\n",
    "var_fakedata_signal_truth = mc_nu_df[mc_nu_df.nuint_categ == 1][var_config.var_nu_col]\n",
    "var_fakedata_signal_truth = np.clip(var_fakedata_signal_truth, var_config.bins[0], var_config.bins[-1] - eps)\n",
    "weight_fakedata_signal_truth = np.ones(len(var_fakedata_signal_truth))\n",
    "nevts_fakedata_signal_truth, _, _ = plt.hist(var_fakedata_signal_truth, bins=var_config.bins, weights=weight_fakedata_signal_truth, histtype=\"step\", label=\"True Signal\")\n",
    "weight_fakedata_signal_truth[mc_nu_df[mc_nu_df.nuint_categ == 1].genie_mode == 0] = qe_scale\n",
    "nevts_fakedata_signal_truth, _, _ = plt.hist(var_fakedata_signal_truth, bins=var_config.bins, weights=weight_fakedata_signal_truth, histtype=\"step\", label=\"QE x{} True Signal\".format(qe_scale))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "Unfold = unfold['unfold']\n",
    "UnfoldCov = unfold['UnfoldCov']\n",
    "Unfold_uncert = np.sqrt(np.diag(UnfoldCov))\n",
    "\n",
    "step_handle, = plt.step(bin_edges, np.append(Unfold, Unfold[-1]), where='post', label='Unfolded', color='black')\n",
    "bar_handle = plt.bar(\n",
    "    bin_centers,\n",
    "    2*Unfold_uncert,\n",
    "    width=(bin_edges[1] - bin_edges[0]) * 1.,\n",
    "    bottom=Unfold - Unfold_uncert,\n",
    "    color='gray',\n",
    "    alpha=0.5,\n",
    "    linewidth=0,\n",
    "    label='Unfolded Stat. error (box)'\n",
    ")\n",
    "reco_handle, = plt.plot(bin_centers, Measured, 'o', label='Reco. signal')\n",
    "Model_smear = unfold['AddSmear'] @ Model\n",
    "true_handle, = plt.plot(bin_centers, Model_smear, 'o', label='$A_c \\\\times$ True signal')\n",
    "Fakedata_Model_smear = unfold['AddSmear'] @ nevts_fakedata_signal_truth*XSEC_UNIT\n",
    "fake_true_handle, = plt.plot(bin_centers, Fakedata_Model_smear, 'o', label='Fake Data')\n",
    "\n",
    "chi2_val = chi2(Unfold, Model_smear, UnfoldCov)\n",
    "chi2_val_fakedata = chi2(Unfold, Fakedata_Model_smear, UnfoldCov)\n",
    "# plt.text(0.95, 0.50, f\"$ \\\\chi^2 = $ {chi2_val:.2f}\", ha='right', va='center', \n",
    "#          transform=plt.gca().transAxes, fontsize=12)\n",
    "\n",
    "# Custom order for legend\n",
    "handles = [step_handle, bar_handle, reco_handle, true_handle, fake_true_handle]\n",
    "labels = [\n",
    "    'Unfolded',\n",
    "    'Unfolded error',\n",
    "    'Reco. signal',\n",
    "    '$A_c \\\\times$Nominal Truth ($\\\\chi^2 = {:.2f}/{}$)'.format(chi2_val, len(var_config.bins)-1),\n",
    "    '$A_c \\\\times$ QE x{} Truth ($\\\\chi^2 = {:.2f}/{}$)'.format(qe_scale, chi2_val_fakedata, len(var_config.bins)-1),\n",
    "]\n",
    "\n",
    "plt.legend(handles, labels, fontsize=12)\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[0])\n",
    "# plt.ylim(0., 5000.)\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-unfolded_event_rates.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig_name = \"{}/{}-{}-add_smear\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "plot_labels = [var_config.var_labels[2], var_config.var_labels[1]]\n",
    "plot_heatmap(unfold[\"AddSmear\"], \"$A_c$\", plot_labels=plot_labels,\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Np background scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "Np_scale = 2\n",
    "weights_fake_data = np.ones(len(var_total_mc))\n",
    "weights_fake_data[mc_evt_df.nuint_categ == 2] = Np_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "mc_stack, _, _ = plt.hist(var_per_nuint_categ_mc,\n",
    "                            bins=var_config.bins,\n",
    "                            weights=weights_per_categ,\n",
    "                            stacked=True,\n",
    "                            color=colors,\n",
    "                            label=mode_labels,\n",
    "                            edgecolor='none',\n",
    "                            linewidth=0,\n",
    "                            density=False,\n",
    "                            histtype='stepfilled')\n",
    "totmc, bin_edges = np.histogram(var_total_mc, bins=var_config.bins, weights=weights_total_mc * weights_fake_data)\n",
    "bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "# use MC as fake data for closure test\n",
    "fake_data = totmc\n",
    "fake_data_err = np.sqrt(totmc)\n",
    "plt.errorbar(bin_centers, fake_data, yerr=fake_data_err, fmt='o', color='black')  # error bars\n",
    "\n",
    "background_cv = mc_stack[-1] - mc_stack[0]\n",
    "# plt.hist(bin_centers, weights=fake_data - background_cv, bins=var_config.bins, histtype=\"step\", color=\"k\", label=\"Background\")\n",
    "\n",
    "accum_sum = [np.sum(data) for data in mc_stack]\n",
    "accum_sum = [0.] + accum_sum\n",
    "total_sum = accum_sum[-1]\n",
    "individual_sums = [accum_sum[i + 1] - accum_sum[i] for i in range(len(accum_sum) - 1)]\n",
    "fractions = [(count / total_sum) * 100 for count in individual_sums]\n",
    "legend_labels = [f\"{label} ({frac:.1f}%)\" for label, frac in zip(mode_labels[::-1], fractions[::-1])]\n",
    "legend_labels.append(\"Fake Data (Np x{})\".format(Np_scale))\n",
    "plt.legend(legend_labels, loc='upper left', fontsize=10, frameon=False, ncol=3, bbox_to_anchor=(0.05, 0.98))\n",
    "\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[1])\n",
    "plt.ylim(0., 1.3 * fake_data.max())\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-topology_breakdown.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect GENIE mode breakdown\n",
    "plt.figure(figsize=(8, 6))\n",
    "mc_stack, _, _ = plt.hist(var_per_genie_mode_mc,\n",
    "                            bins=var_config.bins,\n",
    "                            weights=weights_per_genie_mode,\n",
    "                            stacked=True,\n",
    "                            color=genie_mode_colors,\n",
    "                            label=genie_mode_labels,\n",
    "                            edgecolor='none',\n",
    "                            linewidth=0,\n",
    "                            density=False,\n",
    "                            histtype='stepfilled')\n",
    "\n",
    "totmc, bin_edges = np.histogram(var_total_mc, bins=var_config.bins, weights=weights_total_mc * weights_fake_data)\n",
    "bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "# use MC as fake data for closure test\n",
    "fake_data = totmc\n",
    "fake_data_err = np.sqrt(totmc)\n",
    "# plt.step(bin_edges[:-1], fake_data, where='post', label=\"Data\")  # line\n",
    "plt.errorbar(bin_centers, fake_data, yerr=fake_data_err, fmt='o', color='black')  # error bars\n",
    "\n",
    "accum_sum = [np.sum(data) for data in mc_stack]\n",
    "accum_sum = [0.] + accum_sum\n",
    "total_sum = accum_sum[-1]\n",
    "individual_sums = [accum_sum[i + 1] - accum_sum[i] for i in range(len(accum_sum) - 1)]\n",
    "fractions = [(count / total_sum) * 100 for count in individual_sums]\n",
    "legend_labels = [f\"{label} ({frac:.1f}%)\" for label, frac in zip(genie_mode_labels[::-1], fractions[::-1])]\n",
    "legend_labels.append(\"Fake Data (Np x{})\".format(Np_scale))\n",
    "plt.legend(legend_labels, loc='upper left', fontsize=10, frameon=False, ncol=3, bbox_to_anchor=(0.05, 0.98))\n",
    "\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[1])\n",
    "plt.ylim(0., 1.3 * fake_data.max())\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-genie_mode_breakdown.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake data test -- MC stat + xsec cov\n",
    "C_type = 2\n",
    "Norm_type = 0.5\n",
    "Measured = fake_data * XSEC_UNIT - background_cv * XSEC_UNIT\n",
    "Model = nevts_signal_truth * XSEC_UNIT\n",
    "\n",
    "# use MC stat and xsec cov\n",
    "Covariance_Frac = ret_genie[\"Covariance_Frac\"] + ret_mcstat[\"Covariance_Frac\"]\n",
    "\n",
    "Covariance = np.zeros_like(Covariance_Frac)\n",
    "for i in range(len(var_config.bins)-1):\n",
    "    for j in range(len(var_config.bins)-1):\n",
    "        Covariance[i, j] = Covariance_Frac[i, j] * (nevts_signal_sel_reco[i] * nevts_signal_sel_reco[j]) * XSEC_UNIT**2\n",
    "\n",
    "unfold = WienerSVD(Response, Model, Measured, Covariance, C_type, Norm_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true cross section for alt MC used asfake data\n",
    "var_fakedata_signal_truth = mc_nu_df[mc_nu_df.nuint_categ == 1][var_config.var_nu_col]\n",
    "var_fakedata_signal_truth = np.clip(var_fakedata_signal_truth, var_config.bins[0], var_config.bins[-1] - eps)\n",
    "weight_fakedata_signal_truth = np.ones(len(var_fakedata_signal_truth))\n",
    "nevts_fakedata_signal_truth, _, _ = plt.hist(var_fakedata_signal_truth, bins=var_config.bins, weights=weight_fakedata_signal_truth, histtype=\"step\", label=\"True Signal\")\n",
    "weight_fakedata_signal_truth[mc_nu_df[mc_nu_df.nuint_categ == 1].nuint_categ == 2] = Np_scale\n",
    "nevts_fakedata_signal_truth, _, _ = plt.hist(var_fakedata_signal_truth, bins=var_config.bins, weights=weight_fakedata_signal_truth, histtype=\"step\", label=\"Np x{} True Signal\".format(Np_scale))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "Unfold = unfold['unfold']\n",
    "UnfoldCov = unfold['UnfoldCov']\n",
    "Unfold_uncert = np.sqrt(np.diag(UnfoldCov))\n",
    "\n",
    "step_handle, = plt.step(bin_edges, np.append(Unfold, Unfold[-1]), where='post', label='Unfolded', color='black')\n",
    "bar_handle = plt.bar(\n",
    "    bin_centers,\n",
    "    2*Unfold_uncert,\n",
    "    width=(bin_edges[1] - bin_edges[0]) * 1.,\n",
    "    bottom=Unfold - Unfold_uncert,\n",
    "    color='gray',\n",
    "    alpha=0.5,\n",
    "    linewidth=0,\n",
    "    label='Unfolded Stat. error (box)'\n",
    ")\n",
    "reco_handle, = plt.plot(bin_centers, Measured, 'o', label='Reco. signal')\n",
    "Model_smear = unfold['AddSmear'] @ Model\n",
    "true_handle, = plt.plot(bin_centers, Model_smear, 'o', label='$A_c \\\\times$ True signal')\n",
    "Fakedata_Model_smear = unfold['AddSmear'] @ nevts_fakedata_signal_truth*XSEC_UNIT\n",
    "fake_true_handle, = plt.plot(bin_centers, Fakedata_Model_smear, 'o', label='Fake Data')\n",
    "\n",
    "chi2_val = chi2(Unfold, Model_smear, UnfoldCov)\n",
    "chi2_val_fakedata = chi2(Unfold, Fakedata_Model_smear, UnfoldCov)\n",
    "# plt.text(0.95, 0.50, f\"$ \\\\chi^2 = $ {chi2_val:.2f}\", ha='right', va='center', \n",
    "#          transform=plt.gca().transAxes, fontsize=12)\n",
    "\n",
    "# Custom order for legend\n",
    "handles = [step_handle, bar_handle, reco_handle, true_handle, fake_true_handle]\n",
    "labels = [\n",
    "    'Unfolded',\n",
    "    'Unfolded error',\n",
    "    'Reco. signal',\n",
    "    '$A_c \\\\times$Nominal Truth ($\\\\chi^2 = {:.2f}/{}$)'.format(chi2_val, len(var_config.bins)-1),\n",
    "    '$A_c \\\\times$ Np x{} Truth ($\\\\chi^2 = {:.2f}/{}$)'.format(Np_scale, chi2_val_fakedata, len(var_config.bins)-1),\n",
    "]\n",
    "\n",
    "plt.legend(handles, labels, fontsize=12)\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[0])\n",
    "# plt.ylim(0., 5000.)\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-unfolded_event_rates.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig_name = \"{}/{}-{}-add_smear\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "plot_labels = [var_config.var_labels[2], var_config.var_labels[1]]\n",
    "plot_heatmap(unfold[\"AddSmear\"], \"$A_c$\", plot_labels=plot_labels,\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_scale = 1.2\n",
    "weights_fake_data = np.ones(len(var_total_mc))\n",
    "weights_fake_data[mc_evt_df.nuint_categ == 1] = sig_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "mc_stack, _, _ = plt.hist(var_per_nuint_categ_mc,\n",
    "                            bins=var_config.bins,\n",
    "                            weights=weights_per_categ,\n",
    "                            stacked=True,\n",
    "                            color=colors,\n",
    "                            label=mode_labels,\n",
    "                            edgecolor='none',\n",
    "                            linewidth=0,\n",
    "                            density=False,\n",
    "                            histtype='stepfilled')\n",
    "totmc, bin_edges = np.histogram(var_total_mc, bins=var_config.bins, weights=weights_total_mc * weights_fake_data)\n",
    "bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "# use MC as fake data for closure test\n",
    "fake_data = totmc\n",
    "fake_data_err = np.sqrt(totmc)\n",
    "plt.errorbar(bin_centers, fake_data, yerr=fake_data_err, fmt='o', color='black')  # error bars\n",
    "\n",
    "background_cv = mc_stack[-1] - mc_stack[0]\n",
    "# plt.hist(bin_centers, weights=fake_data - background_cv, bins=var_config.bins, histtype=\"step\", color=\"k\", label=\"Background\")\n",
    "\n",
    "accum_sum = [np.sum(data) for data in mc_stack]\n",
    "accum_sum = [0.] + accum_sum\n",
    "total_sum = accum_sum[-1]\n",
    "individual_sums = [accum_sum[i + 1] - accum_sum[i] for i in range(len(accum_sum) - 1)]\n",
    "fractions = [(count / total_sum) * 100 for count in individual_sums]\n",
    "legend_labels = [f\"{label} ({frac:.1f}%)\" for label, frac in zip(mode_labels[::-1], fractions[::-1])]\n",
    "legend_labels.append(\"Fake Data (Np x{})\".format(sig_scale))\n",
    "plt.legend(legend_labels, loc='upper left', fontsize=10, frameon=False, ncol=3, bbox_to_anchor=(0.05, 0.98))\n",
    "\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[1])\n",
    "plt.ylim(0., 1.3 * fake_data.max())\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-topology_breakdown.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect GENIE mode breakdown\n",
    "plt.figure(figsize=(8, 6))\n",
    "mc_stack, _, _ = plt.hist(var_per_genie_mode_mc,\n",
    "                            bins=var_config.bins,\n",
    "                            weights=weights_per_genie_mode,\n",
    "                            stacked=True,\n",
    "                            color=genie_mode_colors,\n",
    "                            label=genie_mode_labels,\n",
    "                            edgecolor='none',\n",
    "                            linewidth=0,\n",
    "                            density=False,\n",
    "                            histtype='stepfilled')\n",
    "\n",
    "totmc, bin_edges = np.histogram(var_total_mc, bins=var_config.bins, weights=weights_total_mc * weights_fake_data)\n",
    "bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "# use MC as fake data for closure test\n",
    "fake_data = totmc\n",
    "fake_data_err = np.sqrt(totmc)\n",
    "# plt.step(bin_edges[:-1], fake_data, where='post', label=\"Data\")  # line\n",
    "plt.errorbar(bin_centers, fake_data, yerr=fake_data_err, fmt='o', color='black')  # error bars\n",
    "\n",
    "accum_sum = [np.sum(data) for data in mc_stack]\n",
    "accum_sum = [0.] + accum_sum\n",
    "total_sum = accum_sum[-1]\n",
    "individual_sums = [accum_sum[i + 1] - accum_sum[i] for i in range(len(accum_sum) - 1)]\n",
    "fractions = [(count / total_sum) * 100 for count in individual_sums]\n",
    "legend_labels = [f\"{label} ({frac:.1f}%)\" for label, frac in zip(genie_mode_labels[::-1], fractions[::-1])]\n",
    "legend_labels.append(\"Fake Data (Np x{})\".format(sig_scale))\n",
    "plt.legend(legend_labels, loc='upper left', fontsize=10, frameon=False, ncol=3, bbox_to_anchor=(0.05, 0.98))\n",
    "\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[1])\n",
    "plt.ylim(0., 1.3 * fake_data.max())\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-genie_mode_breakdown.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake data test -- MC stat + xsec cov\n",
    "C_type = 2\n",
    "Norm_type = 0.5\n",
    "Measured = fake_data * XSEC_UNIT - background_cv * XSEC_UNIT\n",
    "Model = nevts_signal_truth * XSEC_UNIT\n",
    "\n",
    "# use MC stat and xsec cov\n",
    "Covariance_Frac = ret_genie[\"Covariance_Frac\"] + ret_mcstat[\"Covariance_Frac\"]\n",
    "\n",
    "Covariance = np.zeros_like(Covariance_Frac)\n",
    "for i in range(len(var_config.bins)-1):\n",
    "    for j in range(len(var_config.bins)-1):\n",
    "        Covariance[i, j] = Covariance_Frac[i, j] * (nevts_signal_sel_reco[i] * nevts_signal_sel_reco[j]) * XSEC_UNIT**2\n",
    "\n",
    "unfold = WienerSVD(Response, Model, Measured, Covariance, C_type, Norm_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true cross section for alt MC used asfake data\n",
    "var_fakedata_signal_truth = mc_nu_df[mc_nu_df.nuint_categ == 1][var_config.var_nu_col]\n",
    "var_fakedata_signal_truth = np.clip(var_fakedata_signal_truth, var_config.bins[0], var_config.bins[-1] - eps)\n",
    "weight_fakedata_signal_truth = np.ones(len(var_fakedata_signal_truth))\n",
    "nevts_fakedata_signal_truth, _, _ = plt.hist(var_fakedata_signal_truth, bins=var_config.bins, weights=weight_fakedata_signal_truth, histtype=\"step\", label=\"True Signal\")\n",
    "weight_fakedata_signal_truth[mc_nu_df[mc_nu_df.nuint_categ == 1].nuint_categ == 1] = sig_scale\n",
    "nevts_fakedata_signal_truth, _, _ = plt.hist(var_fakedata_signal_truth, bins=var_config.bins, weights=weight_fakedata_signal_truth, histtype=\"step\", label=\"MEC x{} True Signal\".format(mec_scale))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "Unfold = unfold['unfold']\n",
    "UnfoldCov = unfold['UnfoldCov']\n",
    "Unfold_uncert = np.sqrt(np.diag(UnfoldCov))\n",
    "\n",
    "step_handle, = plt.step(bin_edges, np.append(Unfold, Unfold[-1]), where='post', label='Unfolded', color='black')\n",
    "bar_handle = plt.bar(\n",
    "    bin_centers,\n",
    "    2*Unfold_uncert,\n",
    "    width=(bin_edges[1] - bin_edges[0]) * 1.,\n",
    "    bottom=Unfold - Unfold_uncert,\n",
    "    color='gray',\n",
    "    alpha=0.5,\n",
    "    linewidth=0,\n",
    "    label='Unfolded Stat. error (box)'\n",
    ")\n",
    "reco_handle, = plt.plot(bin_centers, Measured, 'o', label='Reco. signal')\n",
    "Model_smear = unfold['AddSmear'] @ Model\n",
    "true_handle, = plt.plot(bin_centers, Model_smear, 'o', label='$A_c \\\\times$ True signal')\n",
    "Fakedata_Model_smear = unfold['AddSmear'] @ nevts_fakedata_signal_truth*XSEC_UNIT\n",
    "fake_true_handle, = plt.plot(bin_centers, Fakedata_Model_smear, 'o', label='Fake Data')\n",
    "\n",
    "chi2_val = chi2(Unfold, Model_smear, UnfoldCov)\n",
    "chi2_val_fakedata = chi2(Unfold, Fakedata_Model_smear, UnfoldCov)\n",
    "# plt.text(0.95, 0.50, f\"$ \\\\chi^2 = $ {chi2_val:.2f}\", ha='right', va='center', \n",
    "#          transform=plt.gca().transAxes, fontsize=12)\n",
    "\n",
    "# Custom order for legend\n",
    "handles = [step_handle, bar_handle, reco_handle, true_handle, fake_true_handle]\n",
    "labels = [\n",
    "    'Unfolded',\n",
    "    'Unfolded error',\n",
    "    'Reco. signal',\n",
    "    '$A_c \\\\times$Nominal Truth ($\\\\chi^2 = {:.2f}/{}$)'.format(chi2_val, len(var_config.bins)-1),\n",
    "    '$A_c \\\\times$ Signal x{} Truth ($\\\\chi^2 = {:.2f}/{}$)'.format(sig_scale, chi2_val_fakedata, len(var_config.bins)-1),\n",
    "]\n",
    "\n",
    "plt.legend(handles, labels, fontsize=12)\n",
    "plt.xlim(var_config.bins[0], var_config.bins[-1])\n",
    "plt.xlabel(var_config.var_labels[0])\n",
    "# plt.ylim(0., 5000.)\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-unfolded_event_rates.pdf\".format(save_fig_dir, var_config.var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig_name = \"{}/{}-{}-add_smear\".format(save_fig_dir, var_config.var_save_name, syst_name)\n",
    "plot_labels = [var_config.var_labels[2], var_config.var_labels[1]]\n",
    "plot_heatmap(unfold[\"AddSmear\"], \"$A_c$\", plot_labels=plot_labels,\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
